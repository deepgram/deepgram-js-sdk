// This file was auto-generated by Fern from our API Definition.

import type { BaseClientOptions, BaseRequestOptions } from "../../../../../../../../../../../../BaseClient.js";
import {
    type NormalizedClientOptions,
    normalizeClientOptions,
} from "../../../../../../../../../../../../BaseClient.js";
import { mergeHeaders } from "../../../../../../../../../../../../core/headers.js";
import * as core from "../../../../../../../../../../../../core/index.js";
import * as environments from "../../../../../../../../../../../../environments.js";
import { handleNonStatusCodeError } from "../../../../../../../../../../../../errors/handleNonStatusCodeError.js";
import * as errors from "../../../../../../../../../../../../errors/index.js";
import * as Deepgram from "../../../../../../../../../../../index.js";

export declare namespace ModelsClient {
    export interface Options extends BaseClientOptions {}

    export interface RequestOptions extends BaseRequestOptions {}
}

export class ModelsClient {
    protected readonly _options: NormalizedClientOptions<ModelsClient.Options>;

    constructor(options: ModelsClient.Options = {}) {
        this._options = normalizeClientOptions(options);
    }

    /**
     * Retrieves the available think models that can be used for AI agent processing
     *
     * @param {ModelsClient.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @throws {@link Deepgram.BadRequestError}
     *
     * @example
     *     await client.agent.v1.settings.think.models.list()
     */
    public list(
        requestOptions?: ModelsClient.RequestOptions,
    ): core.HttpResponsePromise<Deepgram.AgentThinkModelsV1Response> {
        return core.HttpResponsePromise.fromPromise(this.__list(requestOptions));
    }

    private async __list(
        requestOptions?: ModelsClient.RequestOptions,
    ): Promise<core.WithRawResponse<Deepgram.AgentThinkModelsV1Response>> {
        const _headers: core.Fetcher.Args["headers"] = mergeHeaders(this._options?.headers, requestOptions?.headers);
        const _response = await (this._options.fetcher ?? core.fetcher)({
            url: core.url.join(
                (await core.Supplier.get(this._options.baseUrl)) ??
                    (
                        (await core.Supplier.get(this._options.environment)) ??
                        environments.DeepgramEnvironment.Production
                    ).base,
                "v1/agent/settings/think/models",
            ),
            method: "GET",
            headers: _headers,
            queryParameters: requestOptions?.queryParams,
            timeoutMs: (requestOptions?.timeoutInSeconds ?? this._options?.timeoutInSeconds ?? 60) * 1000,
            maxRetries: requestOptions?.maxRetries ?? this._options?.maxRetries,
            abortSignal: requestOptions?.abortSignal,
            fetchFn: this._options?.fetch,
            logging: this._options.logging,
        });
        if (_response.ok) {
            return { data: _response.body as Deepgram.AgentThinkModelsV1Response, rawResponse: _response.rawResponse };
        }

        if (_response.error.reason === "status-code") {
            switch (_response.error.statusCode) {
                case 400:
                    throw new Deepgram.BadRequestError(_response.error.body as unknown, _response.rawResponse);
                default:
                    throw new errors.DeepgramError({
                        statusCode: _response.error.statusCode,
                        body: _response.error.body,
                        rawResponse: _response.rawResponse,
                    });
            }
        }

        return handleNonStatusCodeError(
            _response.error,
            _response.rawResponse,
            "GET",
            "/v1/agent/settings/think/models",
        );
    }
}
