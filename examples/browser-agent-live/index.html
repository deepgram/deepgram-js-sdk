<!DOCTYPE html>
<html>
  <head>
    <script src="../../dist/umd/deepgram.js"></script>
  </head>
  <body>
    Running test... check the developer console.
    <button type="button">Start</button>
  </body>
  <script>
    const { createClient, AgentEvents } = deepgram;
    const _deepgram = createClient("put yo key here");

    const audioContext = new AudioContext();

    console.log("Deepgram Instance: ", _deepgram);

    (async () => {
      const connection = _deepgram.agent();
      connection.on(AgentEvents.Welcome, () => {
        console.log("WS Connected");
      });
      connection.on(AgentEvents.Open, async () => {
        console.log("Connection opened");

        await connection.configure({
          audio: {
            input: {
              encoding: "opus",
              container: "ogg",
            },
            output: {
              encoding: "linear16",
              bitrate: 48000,
              container: "none",
            },
          },
          agent: {
            listen: {
              model: "nova-2",
            },
            speak: {
              model: "aura-asteria-en",
            },
            think: {
              provider: {
                type: "anthropic",
              },
              model: "claude-3-haiku-20240307",
            },
          },
        });
        console.log("Deepgram Agent configured.");

        setInterval(() => {
          console.log("Keep alive!");
          void connection.keepAlive();
        }, 5000);
      });

      connection.on(AgentEvents.Close, () => {
        console.log("Connection closed");
      });

      connection.on(AgentEvents.UserStartedSpeaking, () => {
        console.log("Interrupting agent.");
      });

      connection.on(AgentEvents.AgentThinking, () => {
        console.log("Agent thinking.");
      });

      connection.on(AgentEvents.AgentStartedSpeaking, () => {
        console.log("Agent started speaking.");
      });

      connection.on(AgentEvents.ConversationText, (data) => {
        console.log(JSON.stringify(data, null, 2));
      });

      connection.on(AgentEvents.Metadata, (data) => {
        console.dir(data);
      });

      connection.on(AgentEvents.Audio, async (data) => {
        console.log("Playing audio.");
        const audioBuffer = await audioContext.decodeAudioData(data);
        const source = audioContext.createBufferSource();
        source.buffer = audioBuffer;
        source.connect(audioContext.destination);
        source.start();
      });

      connection.on(AgentEvents.Error, (err) => {
        console.error("Error!");
        console.error(err);
        console.error(err.message);
      });

      connection.on(AgentEvents.AgentAudioDone, async () => {
        console.log("Agent audio done.");
      });

      connection.on(AgentEvents.Unhandled, (data) => {
        console.dir(data);
      });

      const media = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 48000,
          channelCount: 1,
          echoCancellation: true,
          autoGainControl: true,
          noiseSuppression: false,
        },
        video: false,
      });
      const mic = new MediaRecorder(media, { mimeType: "audio/ogg" });
      const btn = document.querySelector("button");
      console.log(btn);
      btn.addEventListener("click", (event) => {
        if (mic.state === "recording") {
          mic.stop();
          event.target.innerText = "Start";
        } else {
          mic.start();
          event.target.innerText = "Stop";
        }
      });

      mic.onerror = (event) => {
        console.error("Microphone Error:", event.error);
      };

      mic.ondataavailable = async (event) => {
        console.log(mic.mimeType);
        console.log("Data available.");
        await connection.send(event.data);
      };
    })();
    // ...
  </script>
</html>
