/**
 * This file was auto-generated by Fern from our API Definition.
 */

import { mockServerPool } from "../../../../../mock-server/MockServerPool";
import { DeepgramClient } from "../../../../../../src/Client";
import * as Deepgram from "../../../../../../src/api/index";

describe("Models", () => {
    test("list (1)", async () => {
        const server = mockServerPool.createServer();
        const client = new DeepgramClient({
            apiKey: "test",
            environment: { base: server.baseUrl, production: server.baseUrl, agent: server.baseUrl },
        });

        const rawResponseBody = { models: [{ id: "gpt-5", name: "name", provider: "open_ai" }] };
        server
            .mockEndpoint()
            .get("/v1/agent/settings/think/models")
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.agent.v1.settings.think.models.list();
        expect(response).toEqual({
            models: [
                {
                    id: "gpt-5",
                    name: "name",
                    provider: "open_ai",
                },
            ],
        });
    });

    test("list (2)", async () => {
        const server = mockServerPool.createServer();
        const client = new DeepgramClient({
            apiKey: "test",
            environment: { base: server.baseUrl, production: server.baseUrl, agent: server.baseUrl },
        });

        const rawResponseBody = { key: "value" };
        server
            .mockEndpoint()
            .get("/v1/agent/settings/think/models")
            .respondWith()
            .statusCode(400)
            .jsonBody(rawResponseBody)
            .build();

        await expect(async () => {
            return await client.agent.v1.settings.think.models.list();
        }).rejects.toThrow(
            new Deepgram.BadRequestError({
                key: "value",
            }),
        );
    });
});
