// This file was auto-generated by Fern from our API Definition.

import * as Deepgram from "../../../../../../src/api/index";
import { DeepgramClient } from "../../../../../../src/Client";
import { mockServerPool } from "../../../../../mock-server/MockServerPool";

describe("ModelsClient", () => {
    test("list (1)", async () => {
        const server = mockServerPool.createServer();
        const client = new DeepgramClient({ maxRetries: 0, apiKey: "test", environment: server.baseUrl });

        const rawResponseBody = { models: [{ id: "gpt-5", name: "name", provider: "open_ai" }] };
        server
            .mockEndpoint()
            .get("/v1/agent/settings/think/models")
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.agent.v1.settings.think.models.list();
        expect(response).toEqual({
            models: [
                {
                    id: "gpt-5",
                    name: "name",
                    provider: "open_ai",
                },
            ],
        });
    });

    test("list (2)", async () => {
        const server = mockServerPool.createServer();
        const client = new DeepgramClient({ maxRetries: 0, apiKey: "test", environment: server.baseUrl });

        const rawResponseBody = { key: "value" };
        server
            .mockEndpoint()
            .get("/v1/agent/settings/think/models")
            .respondWith()
            .statusCode(400)
            .jsonBody(rawResponseBody)
            .build();

        await expect(async () => {
            return await client.agent.v1.settings.think.models.list();
        }).rejects.toThrow(Deepgram.BadRequestError);
    });
});
